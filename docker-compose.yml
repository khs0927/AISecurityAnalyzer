version: "3.9"

services:
  llm:
    build:
      context: ./infra/docker
      dockerfile: llm-server.Dockerfile
    volumes:
      - ./models:/models
    ports:
      - "7000:7000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:7000/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  agent:
    build:
      context: ./apps/agent
    environment:
      - LLAMA=http://llm:7000/completion
    depends_on:
      llm:
        condition: service_healthy
    ports:
      - "8000:8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/docs || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  api:
    build:
      context: ./apps/api
    depends_on:
      agent:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      - NODE_ENV=production
      - AGENT_URL=http://agent:8000
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  web:
    build:
      context: ./apps/web
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "3000:80"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:80/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  models:
    driver: local 